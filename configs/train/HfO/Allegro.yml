dataset:
  normalize:
    normalize_labels: True
    per_atom: True
    normalize_labels_json: datasets/HfO/atom_graph_rmax6.0_maxneighbor50/normalize_stats.json

  train:
    - src: datasets/HfO/atom_graph_rmax6.0_maxneighbor50/train.lmdb

  valid:
    - src: datasets/HfO/atom_graph_rmax6.0_maxneighbor50/valid.lmdb
  
  test:
    - src: datasets/HfO/atom_graph_rmax6.0_maxneighbor50/test.lmdb

logger: files

task:
  dataset: lmdb_sait
  description: "Regressing to energies and forces for DFT trajectories of HfO"
  metrics: 
    - energy_per_atom_mae
    - energy_per_atom_mse
    - forces_mae
    - forces_mse
  primary_metric: forces_mse
  train_on_free_atoms: False
  eval_on_free_atoms: False

trainer: forces_nequip

model:
  name: allegro
  # neural network
  model_builders:
    - Allegro
    - PerSpeciesRescale
    - ForceOutput
    - RescaleEnergyEtc
  num_layers: 3
  l_max: 2
  parity: o3_full
  BesselBasis_trainable: True
  PolynomialCutoff_p: 6
  env_embed_multiplicity: 32
  env_embed_mlp_latent_dimensions: []
  #env_embed_mlp_nonlinearity: None # if None, comment out
  env_embed_mlp_initialization: uniform
  embed_initial_edge: True
  two_body_latent_mlp_latent_dimensions: [64, 128, 256, 512]
  two_body_latent_mlp_nonlinearity: silu
  two_body_latent_mlp_initialization: uniform
  latent_mlp_latent_dimensions: [512]
  latent_mlp_nonlinearity: silu
  latent_mlp_initialization: uniform
  latent_resnet: True
  edge_eng_mlp_latent_dimensions: [128]
  #edge_eng_mlp_nonlinearity: None # if None, comment out
  edge_eng_mlp_initialization: uniform

  # using data statistics
  # 'auto' requires to set 'initialize' as True, meaning that data statistics will be calculated if the statistics file does not exist
  # if None, comment out
  avg_num_neighbors: auto  
  use_scale_shift: True

  # force
  regress_forces: True

  # graph
  cutoff: 6.0 
  max_neighbors: 50 
  otf_graph: False 
  use_pbc: True

  # data-related arg
  chemical_symbols:
    - O
    - Hf

optim:
  batch_size: 16
  eval_batch_size: 16
  num_workers: 2
  max_epochs: 200

  optimizer: Adam
  optimizer_params: {"amsgrad": False}
  scheduler: LinearLR
  lr_initial: 0.005
  ema_decay: 0.99

  energy_coefficient: 1
  force_coefficient: 1

  # MSE-based loss
  loss_energy: energy_per_atom_mse
  loss_force: force_per_dim_mse

  # MAE-based loss
  #loss_energy: energy_per_atom_mae
  #loss_force: l2mae
