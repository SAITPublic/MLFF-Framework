includes:
- /nas/SAIT-MLFF-Framework/NeurIPS23_DnB/configs/SiN_v1.0/base_rmax5.yml

trainer: forces_nequip

model:
  name: allegro
  cutoff: 5.0
  regress_forces: True
  use_pbc: True
  otf_graph: False

  # neural network
  model_builders:
    - Allegro
    - PerSpeciesRescale
    - ForceOutput
    - RescaleEnergyEtc
  num_layers: 3
  l_max: 2
  parity: o3_restricted #o3_full
  avg_num_neighbors: auto
  BesselBasis_trainable: True
  PolynomialCutoff_p: 6
  env_embed_multiplicity: 16 #32
  env_embed_mlp_latent_dimensions: []
  #env_embed_mlp_nonlinearity: None # if None, comment out
  env_embed_mlp_initialization: uniform
  embed_initial_edge: True
  two_body_latent_mlp_latent_dimensions: [32, 32, 32, 32] #[64, 128, 256, 512]
  two_body_latent_mlp_nonlinearity: silu
  two_body_latent_mlp_initialization: uniform
  latent_mlp_latent_dimensions: [32] #[512]
  latent_mlp_nonlinearity: silu
  latent_mlp_initialization: uniform
  latent_resnet: True
  edge_eng_mlp_latent_dimensions: [32] #[128]
  #edge_eng_mlp_nonlinearity: None # if None, comment out
  edge_eng_mlp_initialization: uniform

  # data-related arg
  chemical_symbols:
    - Si
    - N

optim:
  batch_size: 16 ## GBS = 32 (4 GPUs)
  eval_batch_size: 16
  num_workers: 2
  max_epochs: 300
  ema_decay: 0.99

  optimizer: Adam
  optimizer_params: {"amsgrad": False}
  scheduler: LinearLR
  lr_initial: 0.005
  start_factor: 1.0
  end_factor: 0.0

  energy_coefficient: 1
  loss_energy: energy_per_atom_mse
  force_coefficient: 1
  loss_force: force_per_dim_mse

