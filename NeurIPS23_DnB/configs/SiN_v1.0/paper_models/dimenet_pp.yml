includes:
- NeurIPS23_DnB/configs/SiN_v1.0/base.yml

trainer: forces

model:
  name: dimenetplusplus
  # neural network
  hidden_channels: 128 # github config
  out_emb_channels: 256 # github config
  int_emb_size: 64 # paper, github config 
  basis_emb_size: 8 # paper, github config
  num_blocks: 4 # github config
  num_radial: 6 # OC20 config, github config
  num_spherical: 7 # OC20 config, github config
  num_before_skip: 1 # OC20 config, github
  num_after_skip: 2 # OC20 config, github
  num_output_layers: 3 # OC20 config, github

  # force
  regress_forces: True

  # graph
  cutoff: 6.0 # OC20 config (max neighbor = 50 fixed in model)
  otf_graph: True # True when atom cloud is used
  use_pbc: True # periodic system

optim:
  batch_size: 4
  eval_batch_size: 4
  num_workers: 2
  max_epochs: 200 # 80: GemNet-dT config

  optimizer: Adam # OC20 config (amsgrad = False)

  # OC20-2M : 15 epochs, warmup 2 epoch, milestone 4, 6, 8 epoch
  # WarmupStepLR : OC20 config
  #schduler: LambdaLR
  #lr_lambda: step
  #lr_initial: 1.e-4 # OC20 config
  #lr_gamma: 0.1 # OC20 config
  #lr_milestone_epochs: # can be changed
  #  - 15
  #  - 30
  #  - 45
  #warmup_epochs: 5 # can be changed
  #warmup_factor: 0.2 # OC20 config

  scheduler: LinearLR
  lr_initial: 1.e-4

  # loss function is defined in Eq. (2) in DimeNet paper (ICLR20) 
  energy_coefficient: 1 # OC20 config
  loss_energy: mse # OC20 config (paper: mae)
  force_coefficient: 50 # OC20 config
  loss_force: mse # OC20 config (paper: force_per_dim_mae)
