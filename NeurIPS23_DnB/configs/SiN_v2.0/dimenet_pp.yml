includes:
#- NeurIPS23_DnB/configs/SiN_v2.0/base.yml # atom cloud (without edges)
- NeurIPS23_DnB/configs/SiN_v2.0/base_rmax6_maxneighbor50.yml # atom cloud (without edges)

trainer: forces

model:
  name: dimenetplusplus
  # neural network
  hidden_channels: 192 # OC20 config
  out_emb_channels: 192 # OC20 config
  int_emb_size: 64 # paper 
  basis_emb_size: 8 # paper
  num_blocks: 3 # OC20 config
  num_radial: 6 # OC20 config
  num_spherical: 7 # OC20 config
  num_before_skip: 1 # OC20 config
  num_after_skip: 2 # OC20 config
  num_output_layers: 3 # OC20 config

  # force
  regress_forces: True

  # graph
  cutoff: 6.0 # OC20 config (max neighbor = 50 is fixed in model)
  otf_graph: False # True when atom cloud is used
  use_pbc: True # periodic system

optim:
  # 2 GPU
  batch_size: 2 # can be changed
  eval_batch_size: 2
  num_workers: 2
  max_epochs: 200 # 80: GemNet-dT config

  optimizer: Adam # OC20 config (amsgrad = False)

  # OC20-2M : 15 epochs, warmup 2 epoch, milestone 4, 6, 8 epoch
  # WarmupStepLR : OC20 config
  #schduler: LambdaLR
  #lr_lambda: step
  #lr_initial: 1.e-4 # OC20 config
  #lr_gamma: 0.1 # OC20 config
  #lr_milestone_epochs: # can be changed
  #  - 15
  #  - 30
  #  - 45
  #warmup_epochs: 5 # can be changed
  #warmup_factor: 0.2 # OC20 config

  # SAIT : LinearLR
  #scheduler: LinearLR
  #lr_initial: 1.e-4

  # Warmup then LinearLR
  scheduler: LambdaLR
  lr_lambda: linear
  lr_initial: 1.e-4
  warmup_epochs: 5 
  warmup_factor: 0.2 # OC20 config

  # loss function is defined in Eq. (2) in DimeNet paper (ICLR20) 
  energy_coefficient: 1 # OC20 config
  loss_energy: mse # OC20 config (paper: mae)
  force_coefficient: 50 # OC20 config
  loss_force: mse # OC20 config (paper: force_per_dim_mae)
