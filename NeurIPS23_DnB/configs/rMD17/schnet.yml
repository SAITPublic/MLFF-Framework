includes:
- /nas/SAIT-MLFF-Framework/NeurIPS23_DnB/configs/rMD17/base.yml # atom cloud (without edges)
#- /nas/SAIT-MLFF-Framework/NeurIPS23_DnB/configs/rMD17/base_rmax5.yml # atom graph (with rmax 5.0)

trainer: forces

model:
  name: schnet
  # neural network
  hidden_channels: 64 # paper
  num_filters: 64 # paper
  num_interactions: 3 # paper (suppl.)
  num_gaussians: 50 # paper, resolution 0.1 -> when using cutoff 5.0, it should be 50.
 
  # force
  regress_forces: True 

  # graph
  cutoff: 5.0 # ?? (not avaliable public value)
  otf_graph: True # True when atom cloud is used
  use_pbc: False # non-periodic system

optim:
  batch_size: 32 # paper
  eval_batch_size: 50
  num_workers: 2
  optimizer: Adam # paper
  max_epochs: 3000 # ?? (not available public value), DimeNet revealed it as 100,000 steps
  ema_decay: 0.99 # paper

  # In paper, ExponentialDecay of tensorflow (decaying ...) is used
  # But, decaying step is 100,000 which is identical to max_steps.
  # That is, constant LR is used
  scheduler: ConstantLR 
  lr_initial: 1.e-3 # paper

  # loss function is defined in Eq. (5) in SchNet paper (NeurIPS17)
  energy_coefficient: 0.01
  loss_energy: mse 
  force_coefficient: 1
  #loss_force: l2mae
  loss_force: force_per_dim_mse
